---

copyright:
  years: 2015, 2018
lastupdated: "2018-07-19"

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

此文件適用於 {{site.data.keyword.knowledgestudiofull}} on {{site.data.keyword.cloud}}。若要查看舊版 {{site.data.keyword.knowledgestudioshort}} on {{site.data.keyword.IBM_notm}} Marketplace 的文件，[請按一下此鏈結 ![外部鏈結圖示](../../icons/launch-glyph.svg "外部鏈結圖示")](https://{DomainName}/docs/services/knowledge-studio/build-groundtruth.html){: new_window}。
{: tip}

# 建置基準
{: #build-groundtruth}

註釋專案的目標是取得基準，此為已審核資料的集合，用來將 {{site.data.keyword.watson}} 調整為特定領域。在 {{site.data.keyword.knowledgestudioshort}} 中，註釋人員（一般是目標領域主題的專家）扮演判斷基準的主要角色。
{: shortdesc}

一般工作流程包括下列步驟：

1. 註釋人員提交已註釋的文件以供檢閱。
1. 專案經理（可能是資深領域專家）會檢閱其工作的正確性，並針對註釋人員已註釋並在註釋集之間重疊的文件，比較其一致性。
1. 如果註釋人員內部協議分數太低，則專案經理會拒絕註釋集，並將它退回給註釋人員以進行改善。當註釋集被拒絕時，該集合中的所有文件都會回到可編輯模式。
1. 如果專案經理核准註釋集，則在註釋集之間未重疊的文件會升級成基準，如此一來，該註釋即可用來訓練模型。
1. 專案經理會檢閱重疊的文件，並解決註釋衝突。在此階段中（稱為裁定），團隊可能會檢閱並修訂註釋準則，以協助釐清不同註釋人員在註釋文字時所造成的註釋不正確或不一致的誤會。

    在某些情況下，專案經理可能會希望用來評估註釋人員內部協議的重疊百分比，高於用來裁定差異的重疊百分比。例如，如果註釋人員內部協議看起來很正常，則專案經理可能會決定「可以」將任一註釋升級成基準。

1. 專案經理解決註釋衝突時，已核准的註釋即會升級成基準。

請記住，註釋人員一律需要主觀判斷。註釋準則可以執行很多來確保正確且一致地註釋文字，但是就算是最佳準則也開放進行人工解譯。為取得基準，您會希望花時間來訓練並教育註釋人員，以讓他們在分析領域內容時做出最佳判斷。

## 註釋人員內部協議
{: #wks_haiaa}

註釋人員註釋文件之後，您必須判定哪些文件要升級成基準。從檢閱註釋人員內部協議分數開始。分數低的文件可能會被拒絕，並退回給註釋人員以進行改善。

計算註釋人員內部協議分數時，系統會檢查作業中所有註釋集的所有重疊文件，不論註釋集的狀態為何。在註釋集處於「已提交」狀態之前，您無法接受或拒絕註釋集，因此，在提交所有註釋集之前，您可能不會想要評估註釋人員內部協議，或者您可能想要限制只檢閱已提交其完成註釋集的註釋人員。

註釋人員內部協議分數顯示註釋人員註釋提及項目、關係及互相參照鏈結的差異度。藉由比較一對註釋人員來檢視分數，例如，比較所有 John 提及項目註釋與所有 Mary 提及項目註釋。您也可以藉由比較特定文件來檢視分數，例如，比較 John 在某個文件中所做的關係註釋與 Mary 在相同文件中所做的關係註釋。

為了協助您識別需要調查的區域，如果分數低於您指定的註釋人員內部協議臨界值，則會以紅色強調顯示。在註釋專案的早期階段中，您可能會發現，關係分數通常低於提及項目分數，因為完美的關係註釋需要定義該關係的提及項目先在協議中。

**全部**直欄中的分數是 *Fleiss Kappa 分數*。其代表在作業中所有重疊的文件之間，多位註釋人員套用相同註釋的一致程度。該值範圍上限為 1，甚至是負數，可協助您識別註釋準則或特定註釋人員的弱點。下列準則（*Landis 及 Koch，1977*）提供評量整體效能的起始點。

<table style="width:60%" summary="此表格提供用於評量整體效能的一般註釋人員內部準則。">
  <caption>表 1. 註釋人員內部準則</caption>
  <tr>
    <th style="vertical-align:bottom; text-align:center" id="d12741e148">分數</th>
    <th style="vertical-align:bottom; text-align:center" id="d12741e150">協議層次</th>
  </tr>
  <tr>
    <td style="vertical-align:top; text-align:center" headers="d12741e148">&lt; 0</td>
    <td style="vertical-align:top; text-align:center" headers="d12741e150">極差</td>
  </tr>
  <tr>
    <td style="vertical-align:top; text-align:center" headers="d12741e148">.01 - .20</td>
    <td style="vertical-align:top; text-align:center" headers="d12741e150">差</td>
  </tr>
  <tr>
    <td style="vertical-align:top; text-align:center" headers="d12741e148">.21 - .40</td>
    <td style="vertical-align:top; text-align:center" headers="d12741e150">普通</td>
  </tr>
  <tr>
    <td style="vertical-align:top; text-align:center" headers="d12741e148">.41 - .60</td>
    <td style="vertical-align:top; text-align:center" headers="d12741e150">中等</td>
  </tr>
  <tr>
    <td style="vertical-align:top; text-align:center" headers="d12741e148">.61 - .80</td>
    <td style="vertical-align:top; text-align:center" headers="d12741e150">優良</td>
  </tr>
  <tr>
    <td style="vertical-align:top; text-align:center" headers="d12741e148">.81 - 1.0</td>
    <td style="vertical-align:top; text-align:center" headers="d12741e150">完美</td>
  </tr>
</table>

其他直欄中的分數是 *F1 測量*。其代表一對註釋人員之間的註釋一致性層次。值的範圍從 0 到 1，其中，完美協議以分數 1 表示。可接受協議層次的組成視您的領域資料及類型系統而定。不過，為提供範例，以下是在以 KLUE 類型系統為基礎的專案中，專案經理預期符合或超出的 F1 臨界值：

- 含實體類型的提及項目：0.85
- 關係：0.8
- 互相參照鏈結：0.9

分數的解譯取決於您類型系統的複雜性、已註釋內容的數量及複雜性、註釋人員的經歷以及其他因素。例如，如果註釋作業著重在標示詞性，則您可能會因為已完整定義詞性而預期看到高分。但是，需要更深入分析文字（需要人工解譯）的作業，可能會顯示較低的分數，直到您採取步驟來釐清語義不明確的原因為止。

一般而言，包括許多實體類型及關係類型的類型系統會開放進行更多解譯，因此，在模型開發的早期階段期間，註釋人員內部協議可能會較低。查看分數，即可瞭解哪些實體類型（舉例說明）的分數較低。這些低分指出需要改善註釋準則。藉由查看一對註釋人員之間的分數，您可以識別特定註釋人員是否一致顯示比別人還低的分數。此註釋人員可能在瞭解準則或使用註釋工具上遇到問題，因此可能需要進行額外訓練。

## 檢閱註釋人員內部協議分數
{: #wks_haaccuracy}

決定哪些文件要升級成基準時，您必須檢閱註釋人員內部協議分數。分數低的文件可能會被拒絕，並退回給註釋人員以進行改善。

### 關於此作業
{: #wks_haaccuracy_about}

當您檢查註釋人員內部協議時，也會檢查已由多位註釋人員所註釋的文件。如果文件未在多個註釋集及註釋人員之間共用，則沒有註釋人員內部協議可計算。當您將註釋集新增至作業時，請確定要比較的集合包含相同的重疊文件。您可以藉由開啟**資產** > **文件**頁面，然後按一下**註釋集**標籤，再按一下集合的名稱，來查看哪些文件位於註釋集中。

您可能遇到找不到任何重疊文件的情況。例如，如果您在兩個回合中建立註釋集並將它們新增至相同作業，則可能會發生此情況。即使幾乎同時建立了註釋集，也沒有任何共同文件。而另一個範例是，如果您使用重疊文件來建立註釋集，但每個作業新增一個註釋集，而非將所有註釋集新增至單一作業，則會找不到任何重疊文件，且無法計算註釋人員內部協議。

### 程序
{: #wks_haaccuracy_procedure}

若要評量註釋人員之間的註釋協議，請執行下列動作：

1. 以 {{site.data.keyword.knowledgestudioshort}} 管理者或專案經理身分登入，並選取您的工作區。
1. 選取**機器學習模型** > **註釋作業**頁面，然後開啟您要評估的作業。
1. 按一下**計算註釋人員內部協議**。預設視圖會顯示協議的分數，表示一對註釋人員註釋提及項目的一致程度。第一列顯示每一對註釋人員之間的整體一致性，而下面的表格顯示一對註釋人員在文字中標示特定提及項目的一致程度。
1. 若要探索一對註釋人員註釋關係及互相參照的一致程度，請從第一個功能表中選取**關係**或**互相參照**。
1. 若要探索一對註釋人員在特定重疊文件中註釋實體、關係或互相參照的一致程度，請在第二個功能表中選取**文件**，然後選取您要評估的一對註釋人員。
1. 檢閱分數之後，您可以決定是要核准還是拒絕處於「已提交」狀態中的註釋集。提交註釋集之後，其名稱旁邊即會顯示一個勾選框。請採取下列其中一個動作：

    - 如果註釋人員內部協議分數對註釋集而言是可接受的，請選取勾選框，然後按一下**接受**。不與其他註釋集重疊的文件會升級成基準。必須先透過裁定來檢閱確實重疊的文件，以解決衝突。
    - 如果註釋人員內部協議分數對註釋集而言是不可接受的，請選取勾選框，然後按一下**拒絕**。註釋人員需要重新造訪註釋集，以改善註釋。

## 裁定
{: #wks_haperform}

如果多位註釋人員使用相同的文件，您可能會想要先解決註釋之間的不一致，然後再將註釋升級成基準。此衝突解決程序稱為裁定。

當您核准註釋人員已提交的註釋集時，在註釋集之間沒有重疊的文件會升級成基準。升級重疊的文件之前，您應該先檢查註釋以尋找衝突。找到不一致的實例時，您必須決定如何解決衝突，方法是從註釋人員所套用的註釋中選取正確的註釋，或者選取不同的註釋來套用。

當至少下列其中一個條件為真時，文件即可進行裁定：

- 專案經理同時核准作業中兩個以上的註釋集，且相同的文件存在於其中至少兩個註釋集中（重疊的文件）。
- 專案經理在裁定先前核准之註釋集中的文件之前，先核准另一個註釋集。如果您裁定在註釋集 A 和註釋集 B 之間重疊的文件，將註釋升級成基準，然後核准另一個具有相同文件的註釋集 C，則新核准文件中的註釋會自動升級成基準，因為衝突已不存在。請注意，在註釋集 C 中升級的註釋會置換在裁定註釋集 A 和 B 中的重疊文件時所建立的基準。如果您在升級註釋集 A 和 B 中的註釋之前，先核准註釋集 C ，則可以檢查註釋集 C 中的重疊文件，以尋找衝突並加以裁定。

如果您花時間改善註釋準則，則花費在裁定的時間量可能會減少。您可以藉由提供範例及釐清造成混淆的區域，來協助註釋人員從其錯誤中學習，並防止未來衝突。

以下是註釋人員不同意的各種方法的一些範例：

- **提及項目**

    - Annotator_1 在一段文字上放置一個提及項目；Annotator_2 沒有。
    - Annotator_1 的索引在 Annotator_2 索引之前或之後開始或結束（部分重疊或文字子範圍）。
    - Annotator_1 指派的實體類型不同於 Annotator_2 所指派的實體類型。

- **關係**

    - Annotator_1 在兩個提及項目之間建立一個關係；Annotator_2 沒有。
    - Annotator_1 和 Annotator_2 在相同提及項目之間建立一個關係，但是關係類型不同。
    - Annotator_1 和 Annotator_2 在相同提及項目之間建立一個關係，但是順序相反（少見，因為第一個提及項目與第二個提及項目之間的關係由類型系統所限制）。

- **互相參照鏈結**

    - Annotator_1 版本的互相參照鏈結包括（或排除）Annotator_2 的互相參照鏈結所排除（或包括）的提及項目。Annotator_1 與 Annotator_2 之間的實體對齊會影響評分。

## 解決註釋衝突
{: #wks_haadjudicate}

裁定這一個步驟，容許您先檢閱重疊文件中的註釋衝突，然後再將註釋升級成基準。您可以比較一對註釋人員所新增的註釋，或者比較人工註釋與現行基準。

### 開始之前
{: #wks_haadjudicate_prereq}

按一下[此鏈結 ![外部鏈結圖示](../../icons/launch-glyph.svg "外部鏈結圖示")](https://www.youtube.com/watch?v=EbexfsuXxoQ&amp;feature=youtu.be){: new_window}，觀看一部 3 分鐘的影片，其說明如何裁定文件。

### 關於此作業
{: #wks_haadjudicate_about}

註釋人員完成其註釋作業之後，必須提交他們已完成的註釋集，以供檢閱。當您評估註釋人員內部協議分數時，您可以看到一對註釋人員註釋相同文件的差異度。如果註釋人員內部協議分數是可接受的，則核准註釋集。如果文件在作業中的註釋集之間未重疊，則會將已核准文件中的註釋升級成基準。如果文件在註釋集之間重疊，您應該先裁定文件，並解決所有註釋衝突，然後再將註釋升級成基準。

例如，當您裁定文件時，可能會看到一位註釋人員以實體類型 `PeoplePerson` 來註釋提及項目 `Barack Obama`。另一位註釋人員將相同的文字字串註釋為兩個提及項目，將實體類型 `Person` 指派給 `Barack`，並將實體類型 `Person` 指派給 `Obama`。為協助確保適當地訓練機器學習模型，您應該解決這個不一致。

{{site.data.keyword.knowledgestudioshort}} 支援一次裁定兩個註釋集，或者一次裁定一個註釋集和現行基準。如果文件在超過兩個註釋集之間重疊，請裁定您最有信心的兩個註釋集（或許是因為您對註釋人員較有信心），以判斷要用於文件的基準。然後，根據起始裁定的結果，來裁定剩餘的註釋集。

### 程序
{: #wks_haadjudicate_procedure}

若要檢視重疊的文件及解決衝突，請執行下列動作：

1. 以 {{site.data.keyword.knowledgestudioshort}} 管理者或專案經理身分登入，並選取您的工作區。
1. 選取**機器學習模型** > **註釋作業**頁面，然後開啟您要評估的作業。
1. 確認至少兩個註釋集處於**衝突中**狀態。
1. 按一下**檢查重疊文件的衝突**。即會列出發生衝突的文件。
1. 如果您要忽略重疊文件中的衝突，並在不裁定它們的情況下，將註釋升級成基準，請按一下**接受**。
1. 若要開始解決重疊文件中的衝突，請按一下**檢查衝突**。
1. 如果有三個以上的候選註釋集要進行裁定，包括透過人工註釋和現行基準來註釋的註釋集，請選取您要裁定的兩個候選註釋集，然後按一下**檢查衝突**。如果只有兩個候選註釋集，即會自動啟動裁定工具。

    裁定工具會顯示存在的提及項目、關係及互相參照鏈結衝突的數目。您必須先解決提及項目的衝突，然後才能繼續解決關係與互相參照鏈結之間的衝突。

1. 按一下以強調顯示包含衝突的句子。為了讓您更容易專注在尚未解決的衝突，您可以清除**已解決**勾選框，並確定已選取**尚未解決**勾選框。
1. 按一下個別註釋，然後按一下**接受**或**拒絕**。若要復原您剛才所做的決定，請按 Ctrl+Z。

    您也可以按一下多個註釋，然後按一下以接受或拒絕所有已選取的註釋。如果您決定要取消選取您已選取的註釋，請按一下句子之間的空白處，或按 **Esc** 鍵，來清除您的選擇。

    如果註釋準則先前已連接至專案，且您需要協助來選擇要套用的正確註釋，請按一下**檢視準則**。視管理準則的網站所設定的存取權而定，您可能可以在開啟這些準則（例如，若要新增說明及範例）之後予以更新。
    {: tip}

1. 若要將不同的實體類型套用至提及項目，請拒絕現行註釋，選取提及項目，例如 `Barack Obama`，然後選取正確的實體類型，例如 `Person`。
1. 繼續接受、拒絕及修訂句子中的其他衝突。在解決句子中的所有衝突之後，請按一下**選取所有註釋**鏈結，然後按一下**接受**。
1. 按一下箭頭圖示，以移至下一個句子。繼續進行，直到文件中所有提及項目衝突都已獲解決為止。

    若要儲存進行中的工作，或暫時暫停現行裁定階段作業，請隨時按一下**儲存**。如果要捨棄您所做的所有變更，請按一下**捨棄**。如果您已儲存先前的裁定階段作業，且已準備好繼續進行裁定，請按一下**繼續**以從您上次停止的地方開始裁定衝突。如果您已捨棄先前的裁定階段作業，則必須啟動新的裁定階段作業。
    {: tip}

1. 解決提及項目衝突之後，請切換裁定模式，以解決在關係註釋與互相參照鏈結註釋之間發生的所有衝突。

    - 解決關係模式中的衝突與於解決提及項目衝突的方式類似。您可以逐句解決衝突。
    - 互相參照鏈結可能存在於多個句子之間。當您移至互相參照模式時，系統會在右側窗格中列出每一位註釋人員所建立的互相參照鏈結。選取您要裁定的鏈結，然後按一下**拒絕鏈結**或**接受鏈結**，以拒絕或接受鏈結中的註釋，或按一下**合併鏈結**以合併兩個鏈結。如果您要從互相參照鏈結中移除提及項目，請在文件區域中，按一下提及項目上方標籤中的刪除圖示 (-)。

1. 解決文件中的所有衝突之後，請按一下**升級成基準**。
