---

copyright:
  years: 2015, 2018
lastupdated: "2018-04-04"

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

이 문서는 {{site.data.keyword.knowledgestudiofull}} on {{site.data.keyword.cloud}}에 대한 문서입니다. 이전 {{site.data.keyword.knowledgestudioshort}} on {{site.data.keyword.IBM_notm}} Marketplace 버전에 대한 문서를 보려면 [이 링크 ![외부 링크 아이콘](../../icons/launch-glyph.svg "외부 링크 아이콘")를 클릭하십시오](https://console.bluemix.net/docs/services/knowledge-studio/build-groundtruth.html){: new_window}.
{: tip}

# 기준 실제값 빌드
{: #build-groundtruth}

어노테이션 프로젝트의 목표는 {{site.data.keyword.watson}}을 특정 도메인에 적응시키는 데 사용되는 검증된 데이터의 콜렉션인 기준 실제값을 획득하는 것입니다. {{site.data.keyword.knowledgestudioshort}}에서는 대상 도메인의 주제에 대한 전문가인 사람 어노테이터가 기준 실제값을 판별하는 데 주도적인 역할을 수행합니다.
{: shortdesc}

일반적인 워크플로우는 다음 단계를 포함합니다. 

1. 사람 어노테이터가 어노테이션이 작성된 문서를 검토를 위해 제출합니다. 
1. 프로젝트 관리자(보통 해당 도메인의 전문가)가 작업의 정확도를 검토하고 여러 사람 어노테이터가 어노테이션 세트 간에 겹치는 문서에 어노테이션을 작성한 결과가 얼마나 일관되는지 비교합니다. 
1. 어노테이터 간 일치 점수가 너무 낮은 경우에는 프로젝트 관리자가 어노테이션 세트를 거부하고 이를 개선하도록 사람 어노테이터에게 반환합니다. 어노테이션 세트가 거부되면 해당 세트 내의 모든 문서가 다시 편집 모드로 전환됩니다. 
1. 프로젝트 관리자가 어노테이션 세트를 승인하면 모델을 훈련시키는 데 어노테이션을 사용할 수 있도록 어노테이션 세트 간에 겹치지 않는 문서가 기준 실제값으로 승격됩니다. 
1. 프로젝트 관리자가 겹치는 문서를 검토하고 어노테이션 충돌을 해결합니다. 판정이라고 하는 이 단계에서 팀은 텍스트에 대해 서로 다른 사람 어노테이터 간에 올바르지 않게 또는 일관되지 않게 어노테이션을 작성하도록 한 애매한 부분을 명확하게 하는 데 도움을 주기 위해 어노테이션 가이드라인을 검토하고 개정할 수 있습니다. 

    일부 경우 프로젝트 관리자는 차이점 판정에 대한 겹침 백분율보다 어노테이터 간 일치 평가에 대한 겹침 백분율이 높은 것을 원할 수 있습니다. 예를 들어, 어노테이터 간 일치 상태가 양호한 경우 프로젝트 관리자는 두 어노테이션 모두를 기준 실제값으로 승격시켜도 좋다고 결정할 수 있습니다. 

1. 프로젝트 관리자가 어노테이션 충돌을 해결하면 승인된 어노테이션이 기준 실제값으로 승격됩니다. 

사람에 의한 어노테이션 작성은 항상 판정을 필요로 한다는 점을 기억하십시오. 어노테이션 가이드라인은 텍스트에 올바르고 일관되게 어노테이션을 작성하는 데 큰 역할을 하지만, 최고의 가이드라인에도 해석에 따라 달라질 수 있는 내용이 있습니다. 기준 실제값을 얻기 위해서는 사람 어노테이터가 도메인 컨텐츠를 분석할 때 최선의 판정을 내릴 수 있도록 시간을 들여 교육하고 훈련시켜야 합니다. 

## 어노테이터 간 일치
{: #wks_haiaa}

사람 어노테이터가 문서에 어노테이션을 작성한 후에는 어느 문서를 기준 실제값으로 승격할지 판별해야 합니다. 먼저 어노테이터 간 일치 점수를 검토하십시오. 점수가 낮은 문서는 거부된 후 개선을 위해 사람 어노테이터에게 반환될 가능성이 있는 후보입니다. 

어노테이터 간 일치 점수를 계산할 때, 시스템은 어노테이션 세트의 상태에 관계 없이 태스크에 포함된 모든 어노테이션 세트의 모든 겹치는 문서를 검사합니다. 제출됨 상태가 아니면 어노테이션 세트를 승인하거나 거부할 수 없으므로, 모든 어노테이션 세트가 제출되기 전까지는 어노테이터 간 일치를 평가하지 않거나, 완료된 어노테이션 세트를 제출한 사람 어노테이터로 검토를 제한하는 것이 좋습니다. 

어노테이터 간 일치 점수는 여러 사람 어노테이터가 멘션, 관계 및 상호 참조 체인에 대해 얼마나 다르게 어노테이션을 작성했는지 보여줍니다. 한 쌍의 사람 어노테이터를 비교하여 이 점수를 볼 수 있습니다(예: John의 모든 멘션 어노테이션을 Mary의 모든 멘션 어노테이션과 비교). 특정 문서를 비교하여 이 점수를 볼 수도 있습니다(예: John이 특정 문서에 작성한 관계 어노테이션을 Mary가 동일한 문서에 작성한 관계 어노테이션과 비교). 

조사가 필요한 영역을 식별하는 데 도움을 주기 위해, 어노테이터 간 일치 임계값에 대해 지정한 값보다 낮은 점수는 빨간색으로 강조표시됩니다. 완전 관계 어노테이션에서는 먼저 관계를 정의하는 멘션이 일치해야 하므로, 어노테이션 프로젝트의 초기 단계에서는 보통 관계 점수가 멘션 점수보다 낮은 것을 볼 수 있습니다. 

**전체** 열의 점수는 *Fleiss Kappa 점수*입니다. 이는 태스크 내의 모든 겹치는 문서에서 여러 사람 어노테이터가 얼마나 일관되게 동일한 어노테이션을 적용했는지 나타냅니다. 최대값은 1이며 음수가 될 수도 있는 이 값은 어노테이션 가이드라인 또는 특정 사람 어노테이터의 문제점을 식별하는 데 도움을 줍니다. 다음 가이드라인(*Landis 및 Koch, 1977*)은 전체 성과를 평가하는 시작 지점을 제공합니다. 

<table cellpadding="4" cellspacing="0" summary="" id="wks_haiaa__table_p5s_dx1_f5" class="table" rules="rows" frame="void" border="0"><thead class="thead" align="left"><tr class="row"><th class="entry ncol thleft" align="left" valign="top" id="d12741e148">점수</th>
<th class="entry ncol thleft" align="left" valign="top" id="d12741e150">일치 레벨</th>
</tr>
</thead>
<tbody class="tbody"><tr class="row"><td class="entry ncol tdleft" align="left" valign="top" headers="d12741e148 "><p class="p wrapper">&lt; 0</p></td>
<td class="entry ncol tdleft" align="left" valign="top" headers="d12741e150 "><p class="p wrapper">불량</p></td>
</tr>
<tr class="row"><td class="entry ncol tdleft" align="left" valign="top" headers="d12741e148 "><p class="p wrapper">.01 - .20</p></td>
<td class="entry ncol tdleft" align="left" valign="top" headers="d12741e150 "><p class="p wrapper">매우 낮음</p></td>
</tr>
<tr class="row"><td class="entry ncol tdleft" align="left" valign="top" headers="d12741e148 "><p class="p wrapper">.21 - .40</p></td>
<td class="entry ncol tdleft" align="left" valign="top" headers="d12741e150 "><p class="p wrapper">낮음</p></td>
</tr>
<tr class="row"><td class="entry ncol tdleft" align="left" valign="top" headers="d12741e148 "><p class="p wrapper">.41 - .60</p></td>
<td class="entry ncol tdleft" align="left" valign="top" headers="d12741e150 "><p class="p wrapper">보통</p></td>
</tr>
<tr class="row"><td class="entry ncol tdleft" align="left" valign="top" headers="d12741e148 "><p class="p wrapper">.61 - .80</p></td>
<td class="entry ncol tdleft" align="left" valign="top" headers="d12741e150 "><p class="p wrapper">상당함</p></td>
</tr>
<tr class="row"><td class="entry ncol tdleft" align="left" valign="top" headers="d12741e148 "><p class="p wrapper">.81 - 1.0</p></td>
<td class="entry ncol tdleft" align="left" valign="top" headers="d12741e150 "><p class="p wrapper">완전</p></td>
</tr>
</tbody>
</table>

다른 열의 점수는 *F1 수치*입니다. 이는 사람 어노테이션 쌍 간의 어노테이션 일관성 레벨을 나타냅니다. 이 값의 범위는 0 - 1이며, 여기서 완전 일치는 점수 1로 표시됩니다. 무엇이 허용 가능한 일치 레벨을 구성하는지는 도메인 데이터 및 유형 시스템에 따라 달라집니다. 다음 내용에는 KLUE 유형 시스템을 기반으로 하는 프로젝트에서 프로젝트 관리자가 도달하거나 초과할 것으로 예상하는 F1 임계값의 예가 제공되어 있습니다. 

- 엔티티 유형에 대한 멘션: 0.85
- 관계: 0.8
- 상호 참조 체인: 0.9

이러한 점수의 해석은 유형 시스템의 복잡도, 어노테이션이 작성된 컨텐츠의 양 및 복잡도, 사람 어노테이터의 경험 및 기타 요소에 따라 달라집니다. 예를 들어, 어노테이션 작성 태스크가 품사 레이블 지정에 초점을 맞추고 있는 경우에는 잘 정의된 품사로 인해 높은 점수를 예상할 수 있습니다. 그러나 사람의 해석이 필요한, 더 세부적인 텍스트 분석을 필요로 하는 태스크는 모호성의 원인을 명확하게 하는 조치를 취하기 전까지 낮은 점수를 표시할 수 있습니다. 

일반적으로 많은 엔티티 유형 및 관계 유형을 포함하는 유형 시스템은 해석의 여지가 더 크므로, 모델 개발의 초기 단계에서는 어노테이터 간 일치 레벨이 낮을 수 있습니다. 점수를 보면 어느 엔티티 유형이 점수가 낮은지 등을 볼 수 있습니다. 이러한 낮은 점수는 어노테이션 가이드라인을 개선할 필요가 있음을 나타냅니다. 사람 어노테이터 쌍 간의 점수를 보면 특정 어노테이터가 다른 어노테이터보다 일관되게 낮은 점수를 표시하는지 식별할 수 있습니다. 이 어노테이터는 가이드라인의 이해 또는 어노테이션 도구 사용에 문제가 있어 추가 교육을 받아야 하는 대상입니다. 

## 어노테이터 간 일치 점수 검토
{: #wks_haaccuracy}

어느 문서를 기준 실제값으로 승격할지 판별할 때는 어노테이터 간 일치 점수를 검토해야 합니다. 점수가 낮은 문서는 거부된 후 개선을 위해 사람 어노테이터에게 반환될 가능성이 있는 후보입니다. 

### 이 태스크에 대한 정보

어노테이터 간 일치를 검사할 때는 둘 이상의 사람 어노테이터에 의해 어노테이션이 작성된 문서를 검사합니다. 특정 문서가 여러 어노테이션 세트 및 사람 어노테이터 간에 공유되지 않은 경우에는 계산할 어노테이터 간 일치가 없습니다. 태스크에 어노테이션 세트를 추가할 때는 비교할 세트가 동일한 겹치는 문서를 포함하는지 확인하십시오. **Assets & Tools** > **Documents** 페이지를 열고 **Annotation Sets** 탭을 클릭한 후 세트의 이름을 클릭하여 어느 문서가 어노테이션 세트에 포함되어 있는지 볼 수 있습니다. 

겹치는 문서를 찾을 수 없는 경우가 있습니다. 이는 두 번에 걸쳐 어노테이션 세트를 작성하고 이들을 동일한 세트에 추가하는 경우에 발생할 수 있습니다. 이 경우에는 거의 동일한 시간에 어노테이션 세트가 작성되었지만 공통되는 문서가 없습니다. 다른 예로는, 겹치는 문서가 있는 어노테이션 세트를 작성했으나 하나의 태스크에 모든 어노테이션 세트를 추가하는 대신 태스크당 하나의 어노테이션을 추가하여, 겹치는 문서를 찾을 수 없고 어노테이터 간 일치를 계산할 수 없는 경우가 있습니다. 

### 프로시저

사람 어노테이터 간의 어노테이션 일치를 평가하려면 다음 작업을 수행하십시오. 

1. {{site.data.keyword.knowledgestudioshort}} 관리자 또는 프로젝트 관리자로 로그인하여 작업공간을 선택하십시오. 
1. **Assets & Tools** > **Documents** > **Tasks** 탭을 선택하고 평가할 태스크를 여십시오. 
1. **Calculate Inter-Annotator Agreement**를 클릭하십시오. 기본 보기는 사람 어노테이터 쌍이 얼마나 일관되게 멘션에 어노테이션을 작성했는지에 대한 일치 점수를 표시합니다. 맨 위 행은 각 어노테이터 쌍 간의 전체 일관성을 표시하며 아래 표는 어노테이터 쌍이 텍스트 내의 특정 멘션에 얼마나 일관되게 레이블을 지정했는지를 표시합니다. 
1. 사람 어노테이터 쌍이 얼마나 일관되게 관계 및 상호 참조에 어노테이션을 작성했는지 알아보려면 첫 번째 메뉴에서 **Relation** 또는 **Coreference**를 선택하십시오. 
1. 사람 어노테이터 쌍이 특정 겹치는 문서에서 얼마나 일관되게 엔티티, 관계 또는 상호 참조에 어노테이션을 작성했는지 알아보려면 두 번째 메뉴에서 **Document**를 선택한 후 평가할 어노테이터 쌍을 선택하십시오. 
1. 점수를 검토하고 나면 Submitted 상태의 어노테이션 세트를 승인할지 또는 거부할지 결정할 수 있습니다. 어노테이션 세트가 제출되면 해당 이름 옆에 선택란이 표시됩니다. 다음 조치 중 하나를 수행하십시오. 

    - 어노테이션 세트의 어노테이터 간 일치 점수가 허용 가능한 경우에는 선택란을 선택하고 **Accept**를 클릭하십시오. 다른 어노테이션 세트와 겹치지 않는 문서는 기준 실제값으로 승격됩니다. 겹치는 문서는 먼저 충돌을 해결하기 위해 판정을 통해 검토해야 합니다. 
    - 어노테이션 세트의 어노테이터 간 일치 점수가 허용 불가능한 경우에는 선택란을 선택하고 **Reject**를 클릭하십시오. 해당 어노테이션 세트는 사람 어노테이터의 재작업을 통해 어노테이션을 개선해야 합니다. 

## 판정
{: #wks_haperform}

여러 사람 어노테이터가 동일한 문서에 대해 작업하는 경우에는 어노테이션을 기준 실제값으로 승격하기 전에 불일치를 해결하는 것이 좋습니다. 이러한 충돌 해결 프로세스를 판정이라고 합니다. 

사람 어노테이터가 제출한 어노테이션 세트를 승인하면 어노테이션 세트 간에 겹치지 않는 문서가 기준 실제값으로 승격됩니다. 겹치는 문서를 승격하는 경우에는 먼저 어노테이션에 충돌이 없는지 확인해야 합니다. 이견이 있는 인스턴스를 발견하면 사람 어노테이터가 적용한 어노테이션 중 올바른 어노테이션을 선택하거나, 적용할 다른 어노테이션을 선택하는 등과 같이 충돌을 해결할 방법을 결정해야 합니다. 

다음 조건 중 하나 이상이 참인 경우에는 문서에 대해 판정을 내릴 수 있습니다. 

- 프로젝트 관리지가 한 태스크에 포함된 둘 이상의 어노테이션 세트를 동시에 승인했으며 둘 이상의 어노테이션 세트에 동일한 문서가 있습니다(겹치는 문서). 
- 이전에 승인된 어노테이션 세트의 문서가 판정되기 전에 프로젝트 관리자가 다른 어노테이션 세트를 승인합니다. 어노테이션 세트 A와 어노테이션 세트 B 간에 겹치는 문서를 판정하고, 어노테이션을 기준 실제값으로 승격한 후 동일한 문서가 있는 다른 어노테이션 세트 C를 승인하는 경우에는 더 이상 충돌이 없으므로 새로 승인된 문서가 자동으로 기준 실제값으로 승격됩니다. 어노테이션 세트 C에서 승격된 어노테이션은 어노테이션 세트 A 및 B의 겹치는 문서가 판정될 때 설정된 기준 실제값을 대체한다는 점을 기억하십시오. 어노테이션 세트 A 및 B의 어노테이션을 승격하기 전에 어노테이션 세트 C를 승인하면 세트 C에 있는 겹치는 문서를 포함하여 충돌을 확인하고 판정을 내릴 수 있습니다. 

시간을 투자하여 어노테이션 가이드라인을 개선하면 시간이 지남에 따라 판정에 소요하는 시간이 줄어들 수 있습니다. 예를 제공하고 혼동을 야기하는 영역을 명확하게 하면 사람 어노테이터가 자신의 실수에 대해 학습함으로써 이후 충돌이 발생하지 않도록 하는 데 도움을 줄 수 있습니다. 

사람 어노테이터가 서로 이견을 갖는 유형에 대한 몇 가지 예는 다음과 같습니다. 

- **멘션**

    - Annotator_1은 특정 범위의 텍스트에 대해 멘션을 작성하고 Annotator_2는 작성하지 않습니다. 
    - Annotator_1의 색인이 Annotator_2의 색인 앞 또는 뒤에서 시작하거나 끝납니다(부분적 텍스트 겹침 또는 하위 범위가 있음). 
    - Annotator_1이 Annotator_2가 지정하는 엔티티 유형과 다른 엔티티 유형을 지정합니다. 

- **관계**

    - Annotator_1은 두 멘션 간에 관계를 작성하고 Annotator_2는 작성하지 않습니다. 
    - Annotator_1과 Annotator_2가 동일한 멘션 간에 관계를 작성하지만 관계 유형이 다릅니다. 
    - Annotator_1과 Annotator_2가 동일한 멘션 간에 관계를 작성하지만 순서가 반대입니다(첫 번째 멘션과 두 번째 멘션 간의 관계는 유형 시스템에 의해 제한되므로 이 경우는 희귀함). 

- **상호 참조 체인**

    - Annotator_1의 상호 참조 체인 버전이 Annotator_2의 상호 참조 체인이 제외(또는 포함)한 멘션을 포함(또는 제외)합니다. Annotator_1과 Annotator_2 간의 엔티티 배열이 스코어링 문제가 됩니다. 

## 어노테이션 충돌 해결
{: #wks_haadjudicate}

판정은 어노테이션을 기준 실제값으로 승격하기 전에 겹치는 문서의 어노테이션 충돌을 검토할 수 있게 해 주는 단계입니다. 사용자는 사람 어노테이터 쌍이 추가한 어노테이션을 비교하거나, 사람이 작성한 어노테이션을 현재 기준 실제값과 비교할 수 있습니다. 

### 시작하기 전에

[이 링크 ![외부 링크 아이콘](../../icons/launch-glyph.svg "외부 링크 아이콘")](https://www.youtube.com/watch?v=EbexfsuXxoQ&amp;feature=youtu.be){: new_window}를 클릭하여 문서 판정 방법을 보여주는 3분 분량의 동영상을 보십시오. 

### 이 태스크에 대한 정보

사람 어노테이터는 어노테이션 작성 태스크를 완료하고 나면 완료한 어노테이션 세트를 검토를 위해 제출해야 합니다. 어노테이터 간 일치 점수를 평가하면 어노테이터 쌍이 동일한 문서에 얼마나 다르게 어노테이션을 작성했는지 볼 수 있습니다. 어노테이터 간 일치 점수가 허용 가능한 경우에는 어노테이션 세트를 승인합니다. 문서가 태스크 내의 어노테이션 세트 간에 겹치지 않는 경우에는 승인된 문서의 어노테이션이 기준 실제값으로 승격됩니다. 문서가 어노테이션 세트 간에 겹치는 경우에는 어노테이션을 기준 실제값으로 승격하기 전에 문서를 판정하고 존재하는 어노테이션 충돌을 해결해야 합니다. 

예를 들어, 문서를 판정할 때 한 어노테이터가 멘션 `Barack Obama`에 엔티티 유형 `PeoplePerson`으로 어노테이션을 작성한 것을 발견했습니다. 다른 어노테이터는 동일한 텍스트 문자열을 두 멘션으로 어노테이션 작성하면서 엔티티 유형 `Person`을 `Barack`에, 엔티티 유형 `Person`을 `Obama`에 지정했습니다. 기계 학습 모델이 올바르게 훈련되도록 하려면 이 불일치를 해결해야 합니다. 

{{site.data.keyword.knowledgestudioshort}}는 한 번에 두 어노테이션 세트 간에 판정을 내리거나, 한 어노테이션 세트와 현재 기준 실제값 간에 판정을 내리는 기능을 지원합니다. 문서가 셋 이상의 어노테이션 세트에서 겹치는 경우에는 가장 신뢰할 수 있는 두 어노테이션 세트(해당 사람 어노테이터에 대한 신뢰가 더 높다는 등의 이유로) 간에 판정을 수행하여 문서의 기준 실제값을 결정하십시오. 그 후 첫 판정의 결과를 기반으로 나머지 어노테이션 세트의 판정을 수행하십시오. 

### 프로시저

겹치는 문서를 보고 충돌을 해결하려면 다음 작업을 수행하십시오. 

1. {{site.data.keyword.knowledgestudioshort}} 관리자 또는 프로젝트 관리자로 로그인하여 작업공간을 선택하십시오. 
1. **Assets & Tools** > **Documents** > **Tasks** 탭을 선택하고 평가할 태스크를 여십시오. 
1. 둘 이상의 어노테이션 세트가 **In conflict** 상태인지 확인하십시오. 
1. **Check Overlapping Documents for Conflicts**를 클릭하십시오. 충돌하는 문서가 나열됩니다. 
1. 겹치는 문서의 충돌을 무시하고 어노테이션을 판정 없이 기준 실제값으로 승격하려면 **Accept**를 클릭하십시오. 
1. 겹치는 문서의 충돌 해결을 시작하려면 **Check for Conflicts**를 클릭하십시오. 
1. 사람에 의한 어노테이션 작성을 통해 어노테이션 작성된 어노테이션 세트 및 현재 기준 실제값을 포함하여 판정 후보가 셋 이상인 경우에는 판정을 수행할 두 후보를 선택하고 **Check for Conflicts**를 클릭하십시오. 후보가 둘 뿐인 경우에는 판정 도구가 자동으로 시작됩니다. 

    판정 도구는 존재하는 멘션, 관계 및 상호 참조 체인 충돌의 수를 보여줍니다. 관계 및 상호 참조 체인 간의 충돌을 해결하려면 먼저 멘션 충돌을 해결해야 합니다. 

1. 클릭하여 충돌을 포함하는 문장을 강조표시하십시오. 해결되지 않은 충돌을 더 쉽게 알아볼 수 있도록 하기 위해 **Resolved** 선택란을 선택 취소하고 **Unresolved** 선택란을 선택할 수도 있습니다. 
1. 개별 어노테이션을 클릭한 후 **Accept** 또는 **Reject**를 클릭하십시오. 방금 내린 결정을 실행 취소하려면 `Ctrl+Z`를 누르십시오. 

    둘 이상의 어노테이션을 클릭한 후 선택한 어노테이션을 모두 승인하거나 거부하도록 클릭할 수도 있습니다. 선택한 어노테이션을 선택 취소하려는 경우에는 문장 간의 빈 공간을 클릭하거나 **Esc** 키를 눌러 선택을 취소하십시오. 

    이전에 어노테이션 가이드라인이 프로젝트에 연결되어 있었으며 적용할 어노테이션을 선택하는 데 도움이 필요한 경우에는 **View Guidelines**를 클릭하십시오. 가이드라인이 호스팅되는 사이트에 설정된 액세스 권한에 따라, 가이드라인을 연 후 이를 업데이트(예: 설명 및 예 추가)할 수도 있습니다.
    {: tip}

1. 멘션에 다른 엔티티 유형을 적용하려면 현재 어노테이션을 거부하고, 멘션(예: `Barack Obama`)을 선택한 후 올바른 엔티티 유형(예: `Person`)을 선택하십시오. 
1. 문장 내의 다른 충돌을 계속해서 검토하면서 승인하거나 거부하십시오. 문장 내의 모든 충돌을 해결한 후에는 **Select all annotations** 링크를 클릭한 후 **Accept**를 클릭하십시오. 
1. 화살표 아이콘을 클릭하여 다음 문장으로 이동하십시오. 문서 내의 모든 멘션 충돌이 해결될 때까지 계속하십시오. 

    진행 중인 작업을 저장하거나, 현재 판정 세션을 일시중단하려면 언제든지 **Save**를 클릭하십시오. 수행한 모든 변경을 취소하려는 경우에는 **Discard**를 클릭하십시오. 이전 판정 세션을 저장한 후 판정을 재개할 준비가 된 경우에는 **Resume**을 클릭하여 마지막으로 중지한 위치에서 판정을 시작하십시오. 이전 판정 세션을 버린 경우에는 새 판정 세션을 시작해야 합니다.
    {: tip}

1. 멘션 충돌을 해결한 후에는 판정 모드로 전환하여 관계 어노테이션 및 상호 참조 체인 어노테이션 간에 발생한 모든 충돌을 해결하십시오. 

    - 관계 모드의 충돌 해결은 멘션 충돌 해결 방법과 유사합니다. 사용자는 각 문장을 기반으로 충돌을 해결합니다. 
    - 상호 참조 체인은 여러 문장 간에 존재할 수 있습니다. 상호 참조 모드로 전환하면 시스템이 오른쪽에 있는 분할창에 각 사람 어노테이터가 작성한 상호 참조 체인을 나열합니다. 판정할 체인을 선택한 후 **Reject Chain** 또는 **Accept Chain**을 클릭하여 체인 내의 어노테이션을 거부 또는 승인하거나, **Merge Chains**를 클릭하여 두 체인을 병합하십시오. 상호 참조 체인에서 멘션을 제거하려는 경우에는 문서 영역의 멘션 위에 있는 레이블에서 삭제 아이콘(-)을 클릭하십시오. 

1. 문서 내의 모든 충돌이 해결되고 나면 **Promote to Ground Truth**를 클릭하십시오. 
